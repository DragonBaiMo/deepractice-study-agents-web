---
title: "章节概览"
description: "第三章 大语言模型与智能体"
---

# 第三章 大语言模型与智能体

## 章节导览

| 节次 | 标题 | 核心内容 | 阅读时间 |
|:---:|------|----------|:--------:|
| 3.1 | [语言模型简史](3.1-语言模型简史.md) | 从N-gram到Transformer，涌现与心智社会 | 15分钟 |
| 3.2 | [提示工程基础](3.2-Prompt工程基础.md) | System Prompt设计、上下文鸿沟与DPML预告 | 40分钟 |
| 3.3 | [LLM的能力与边界](3.3-LLM的能力与边界.md) | 推理分层(CoT vs o1/o3)、RAG与记忆的区别 | 25分钟 |
| 3.4 | [从LLM到智能体架构](3.4-从LLM到智能体架构.md) | 四层架构、模型选择(2025-2026)、认知架构预告 | 30分钟 |
| 3.5 | [习题与讨论](3.5-习题与讨论.md) | 概念理解、设计实践、思考探索 | 45分钟 |

总计阅读时间:约155分钟

---

## 章节概述

本章聚焦于现代智能体的核心组件——大语言模型(LLM),系统介绍其工作原理、交互技术和应用边界。

**四个核心问题**:

1. **语言模型如何演进?** (3.1节)
   从统计语言模型到Transformer，理解"涌现"现象与心智社会理论的关联

2. **如何有效交互?** (3.2节)
   掌握提示工程设计原则，理解Prompt的本质是"传递认知框架"而非"传递信息"

3. **LLM能做什么?不能做什么?** (3.3节)
   区分推理能力的两个层次，思考RAG与真正"记忆"的本质区别

4. **如何构建智能体架构?** (3.4节)
   从功能架构到认知架构，理解智能体设计的两个视角

---

## 本章亮点

### 理论升华
- **涌现与心智社会**：连接明斯基理论与现代多智能体系统
- **上下文鸿沟**：识别AI不知道但角色必须知道的信息
- **RAG不是记忆**：检索与联想的本质区别

### 技术更新(2025-2026)
- **推理增强模型**：o1/o3系列的"内部思考"范式
- **模型分类**：通用旗舰 / 推理增强 / 性价比 / 快速响应
- **混合策略**：简单任务用快速模型，关键决策用推理模型

### 后续章节预留接口

| 概念 | 本章引入位置 | 深入章节 |
|-----|-------------|---------|
| 上下文鸿沟 | 3.2节 Prompt本质 | [第四章 PromptX](../chapter04/4.2-上下文鸿沟.md) |
| Engram记忆网络 | 3.3节 RAG质疑 | [第四章 Engram](../chapter04/4.5-Engram记忆网络.md) |
| 事件驱动架构 | 3.4节 智能体架构 | [第五章 AgentX](../chapter05/README.md) |
| 认知架构 | 3.4节 功能vs认知 | [第九章 Monogent](../chapter09/README.md) |

---

## 学习目标

完成本章学习后,读者应能够:
- 理解大语言模型的技术演进脉络，以及"涌现"的深层含义
- 设计完整的智能体提示系统，识别并填补上下文鸿沟
- 区分推理能力的不同层次，理解RAG与记忆的本质区别
- 规划智能体架构，在功能视角与认知视角之间建立连接
- 根据任务特征选择合适的模型（2025-2026主流模型）

---

[上一章:智能体发展史](../chapter02/README.md) | [下一章:PromptX 智能体上下文平台](../chapter04/README.md)
