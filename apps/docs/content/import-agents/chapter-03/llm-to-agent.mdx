---
title: "从LLM到智能体架构"
description: "3.4 从LLM到智能体架构"
---

# 3.4 从LLM到智能体架构

上一节我们看到了大语言模型的四大局限：知识截断、幻觉、计算弱、不会执行。这些局限看似棘手，但解决思路其实很清晰——**用架构来弥补模型的不足**。

这就是智能体存在的意义：让模型专注于它擅长的"理解和推理"，把它不擅长的事情交给专门的工具和机制来处理。

---

## 3.4.1 智能体如何弥补LLM的不足

每一个局限都有对应的解决方案：

| 大语言模型局限 | 表现形式 | 智能体增强方案 | 关键技术 | 参考章节 |
|--------------|---------|---------------|---------|----------|
| 知识截断 | 不知道训练后的新信息 | 实时信息检索 | RAG | 第8章 |
| 幻觉问题 | 编造虚假但看似合理的信息 | 工具验证+反思 | Tool Calling, Reflection | 第4章 |
| 计算能力不足 | 数学计算频繁出错 | 专用工具调用 | Function Calling | 第4章 |
| 缺乏执行能力 | 只能生成文本,不能操作 | 执行器集成 | Tool Execution | 第4章 |

### 智能体的四层架构

把这些解决方案组合起来，就形成了智能体的四层架构：

```
用户输入:"帮我查询北京天气,如果是晴天就预订明天的故宫门票"
    ↓
┌──────────────────────────────────────────┐
│  推理层:大语言模型(LLM)                    │
│  - 理解复杂意图:天气查询+条件判断+预订       │
│  - 任务分解:先查天气 → 判断条件 → 执行预订  │
│  - 生成执行计划                            │
└──────────────────────────────────────────┘
    ↓
┌──────────────────────────────────────────┐
│  工具层:外部工具集成                        │
│  - weather_api: 查询实时天气 ✓             │
│  - booking_api: 预订景区门票 ✓             │
│  - calculator: 费用计算 ✓                  │
└──────────────────────────────────────────┘
    ↓
┌──────────────────────────────────────────┐
│  记忆层:上下文管理                          │
│  - 短期记忆:当前会话的对话历史              │
│  - 长期记忆:用户历史偏好、订单记录           │
└──────────────────────────────────────────┘
    ↓
┌──────────────────────────────────────────┐
│  反思层:质量保证                            │
│  - 信息验证:天气数据是否为最新?             │
│  - 执行检查:预订操作是否成功?               │
│  - 错误修正:失败时尝试备选方案              │
└──────────────────────────────────────────┘
    ↓
输出:"北京明天天气晴朗,已为您预订故宫门票(成人票×1),订单号:20251217001"
```

### 四个增强维度详解

#### 维度一：知识时效性增强(RAG)

模型不知道新信息？让它先"查资料"再回答：

```python
# 步骤1: 使用搜索工具检索实时信息
search_result = search_tool("2024巴黎奥运会金牌榜")

# 步骤2: 将检索结果作为上下文注入提示词
prompt = f"""
根据以下最新信息回答问题:

检索结果:
{search_result}

问题:2024年巴黎奥运会金牌榜前三名分别是哪些国家?
"""

# 步骤3: 大语言模型基于最新信息生成答案
answer = llm.generate(prompt)  # ✓ 获得准确的最新答案
```

#### 维度二：信息可靠性增强(工具验证)

模型会编造信息？让它用工具查真实数据，而不是"凭空想象"：

```python
class TravelAgent:
    def recommend_cafe(self, city, keyword):
        # 步骤1: 识别需要外部信息
        thought = "用户需要咖啡馆推荐,应使用搜索工具获取真实信息,而非基于推测"

        # 步骤2: 调用搜索工具获取真实数据
        results = self.search_tool(f"{city} {keyword} 咖啡馆")

        # 步骤3: 基于真实搜索结果生成回答
        if not results:
            return "抱歉,未找到符合条件的咖啡馆信息。"
        else:
            return self.llm.generate(
                f"根据以下搜索结果进行推荐:\n{results}"
            )  # ✓ 基于真实数据,减少幻觉风险
```

#### 维度三：计算准确性增强(专用工具)

模型算术不行？让它调用计算器：

```python
class MathAgent:
    def solve(self, expression):
        # 步骤1: 判断是否为计算任务
        if self._is_calculation(expression):
            # 步骤2: 调用计算器工具获得精确结果
            result = self.calculator_tool.eval(expression)  # ✓ 精确计算
            return f"{expression} = {result}"

        # 步骤3: 对于数学推理题,交由大语言模型处理
        elif self._is_math_reasoning(expression):
            return self.llm.solve_reasoning(expression)

        else:
            return "无法识别的数学问题类型"
```

#### 维度四：实际执行力增强(执行器)

模型只会说不会做？让它生成内容，让工具去执行：

```python
class EmailAgent:
    def send_email(self, recipient, subject, key_points):
        # 步骤1: 使用大语言模型生成邮件内容
        content = self.llm.generate(
            f"撰写一封给{recipient}的{subject}邮件,要点包括:{key_points}"
        )

        # 步骤2: 调用邮件API真正发送邮件
        send_result = self.email_api.send(
            to=recipient,
            subject=subject,
            body=content,
            cc=self.config.get('default_cc')
        )  # ✓ 邮件真正被发送

        # 步骤3: 返回执行状态
        if send_result.success:
            return f"邮件已成功发送至{recipient},消息ID:{send_result.message_id}"
        else:
            return f"邮件发送失败:{send_result.error_message}"
```

---

## 3.4.2 如何选择大语言模型

不同场景需要不同模型，合理选择可以在性能和成本之间取得平衡。

### 主流模型一览（2025-2026）

| 模型名称 | 核心优势 | 典型应用场景 | 相对成本 |
|---------|---------|-------------|---------|
| **通用旗舰** | | | |
| GPT-5/5.1/5.2 | 推理与生成能力均衡，原生多模态 | 复杂智能体任务 | 高 |
| Claude Opus 4.5 | 超长上下文(200K+)，编程能力突出 | 代码智能体、文档分析 | 高 |
| Gemini 3 Pro | 多模态原生，推理能力强 | 图文混合任务、科学推理 | 中高 |
| **推理增强** | | | |
| o3/o3-mini | 内部推理+自我验证，复杂问题求解 | 数学证明、科学研究 | 极高/中 |
| Claude thinking | 扩展思考模式，复杂规划 | 架构设计、决策分析 | 高 |
| **性价比首选** | | | |
| DeepSeek-V3 | 极低成本($0.27/百万token) | 大规模部署、成本敏感场景 | 极低 |
| Llama 3.3/4 | 开源可本地部署 | 隐私敏感、离线场景 | 低(自部署) |
| Qwen 2.5 | 中文理解能力优 | 中文智能体 | 低 |
| **快速响应** | | | |
| GPT-4o-mini | 响应快、成本低 | 简单任务、高频调用 | 极低 |
| Claude Haiku 3.5 | 极速响应 | 实时交互、工具调用 | 极低 |

### 怎么选？看这棵决策树

```
                        任务需要深度推理(数学证明/科学研究)?
                        /                              \
                    是/                                否\
                     ↓                                  ↓
             o3 / o3-mini                    任务涉及多模态(图像/视频)?
             Claude thinking                 /                      \
                                         是/                        否\
                                          ↓                          ↓
                                   Gemini 3 Pro              主要处理中文?
                                   GPT-5 Vision              /          \
                                                         是/            否\
                                                          ↓              ↓
                                                    Qwen 2.5      需要超长上下文?
                                                    DeepSeek      /            \
                                                              是/              否\
                                                               ↓                ↓
                                                        Claude Opus       成本敏感?
                                                                          /      \
                                                                      是/        否\
                                                                       ↓          ↓
                                                                DeepSeek-V3   GPT-5
                                                                GPT-4o-mini   Claude
```

**实用建议**：
- **原型开发阶段**：用GPT-4o-mini或Haiku快速迭代
- **生产部署阶段**：根据任务特征选择专业模型
- **混合策略**：简单任务用快速模型，关键决策用推理模型验证

### 成本优化的两个技巧

#### 技巧一：分级调用

简单问题用便宜模型，复杂问题才用贵的：

```python
class SmartAgent:
    def __init__(self):
        self.fast_model = "gpt-4o-mini"    # 快速廉价模型
        self.strong_model = "claude-opus-4-5"  # 强大昂贵模型
        self.reasoning_model = "o3-mini"    # 推理增强模型

    def think(self, task):
        # 简单任务使用小模型
        if self._is_simple_task(task):
            return self.call_llm(self.fast_model, task)
        # 需要深度推理的任务使用推理模型
        elif self._requires_reasoning(task):
            return self.call_llm(self.reasoning_model, task)
        # 复杂但不需要深度推理的任务使用通用强模型
        else:
            return self.call_llm(self.strong_model, task)

    def _is_simple_task(self, task):
        """判断任务复杂度"""
        return (len(task) < 100 and
                not self._requires_multi_step_reasoning(task))

    def _requires_reasoning(self, task):
        """判断是否需要深度推理"""
        reasoning_keywords = ["证明", "推导", "分析原因", "为什么"]
        return any(kw in task for kw in reasoning_keywords)
```

#### 技巧二：响应缓存

相同的问题不要重复调用，用缓存省钱：

```python
import hashlib
import json

class CachedAgent:
    def __init__(self):
        self.cache = {}  # 简单内存缓存,生产环境应使用Redis等
        self.cache_ttl = 3600  # 缓存有效期(秒)

    def think(self, prompt):
        # 计算提示词的哈希值作为缓存键
        cache_key = hashlib.md5(
            json.dumps(prompt, sort_keys=True).encode()
        ).hexdigest()

        # 检查缓存
        if cache_key in self.cache:
            cached_response, timestamp = self.cache[cache_key]
            if time.time() - timestamp < self.cache_ttl:
                return cached_response  # 命中缓存,无需调用API

        # 缓存未命中,调用大语言模型
        response = self.llm.generate(prompt)

        # 存入缓存
        self.cache[cache_key] = (response, time.time())
        return response
```

---

## 3.4.3 大语言模型的发展趋势

了解模型的发展方向，可以帮助我们设计更有前瞻性的智能体架构。

### 趋势一：推理增强模型

OpenAI的o1系列模型开创了新范式：模型在给出答案前先进行"内部推理"[1]。

```python
# 传统模型
Q: "这道数学应用题怎么解?"
A: [直接生成答案] (容易出错)

# 推理增强模型
Q: "这道数学应用题怎么解?"
A: [内部执行多步推理] → [自我验证] → [输出经过验证的解法]
```

这对智能体意味着：幻觉会减少（模型会自我验证），规划能力会增强，但调用成本也会上升（内部推理消耗更多token）。

### 趋势二：原生工具调用能力

新一代模型将工具调用作为原生能力，无需复杂的提示词工程：

```python
# 传统方式:需要在System Prompt中详细描述工具格式
system_prompt = """
可用工具:
- calculator(expression: str): 计算数学表达式
- search(query: str): 搜索网络信息
输出格式:{"tool": "工具名", "parameters": {...}}
"""

# 新方式:直接传入工具定义,模型原生理解
tools = [
    {
        "type": "function",
        "function": {
            "name": "calculator",
            "description": "执行数学表达式计算",
            "parameters": {
                "type": "object",
                "properties": {
                    "expression": {
                        "type": "string",
                        "description": "要计算的数学表达式"
                    }
                },
                "required": ["expression"]
            }
        }
    }
]

response = llm.chat(messages, tools=tools)
# 模型直接输出结构化的tool_calls,无需额外解析
```

### 趋势三：多模态智能体

未来的智能体不仅能处理文本，还能理解图像、视频、音频：

```python
# 多模态智能体示例
agent.run([
    {"type": "text", "content": "分析这个网页的用户体验设计"},
    {"type": "image", "content": screenshot_data},
    {"type": "text", "content": "生成改进建议和修改方案"}
])

# 输出:文字分析报告 + 标注图片 + 代码修改建议
```

---

## 3.4.4 从功能架构到认知架构

到目前为止，我们讨论的都是**功能视角**——模型有什么能力、工具能做什么、如何弥补不足。这是构建智能体的起点，但不是终点。

### 功能架构的局限

功能架构回答的是"**怎么做**"的问题：
- 怎么调用工具？→ Function Calling
- 怎么获取实时信息？→ RAG
- 怎么保存对话历史？→ Memory

但它不回答"**如何思考**"的问题：
- 智能体应该如何理解任务？
- 如何做出决策？
- 如何从经验中学习？

### 认知架构的视角

**认知架构**关注的是智能体的"心智结构"——它如何感知、思考、记忆、决策。

```
功能架构视角                 认知架构视角
─────────────                ─────────────
工具调用模块                 感知-理解-行动循环
记忆存储模块                 工作记忆 + 长期记忆
推理引擎模块                 元认知 + 反思机制
```

这两个视角并不矛盾——功能架构是"骨骼"，认知架构是"灵魂"。一个好的智能体需要两者兼备。

> **预告：Monogent认知架构**
>
> 在第九章，我们将介绍一种完整的认知架构设计——**Monogent**。它不仅定义了智能体的功能模块，还定义了智能体的认知过程：
>
> - **认知循环**：感知 → 理解 → 规划 → 执行 → 反思
> - **记忆系统**：工作记忆 + 语义记忆 + 情景记忆
> - **元认知**：对自身思考过程的监控和调节
>
> 从功能架构到认知架构，是智能体设计从"会做事"到"会思考"的跃迁。

---

## 本节小结

智能体架构的本质是**用架构弥补模型的不足**：

| 模型局限 | 智能体方案 | 核心技术 |
|---------|---------|---------|
| 知识截断 | 实时检索 | RAG |
| 幻觉 | 工具验证 | Tool Calling |
| 计算弱 | 专用工具 | Function Calling |
| 不会执行 | 执行器 | Tool Execution |

模型选择方面，根据任务特征（多模态、语言、上下文长度、推理复杂度）选择合适的模型，并通过分级调用和响应缓存降低成本。

大语言模型是智能体的"大脑"，但只有通过架构赋予它"工具"、"记忆"和"反思"机制，才能构建真正可靠的智能系统。

在下一章中，我们将开始动手实践，构建第一个完整的智能体系统。

---

## 参考文献

[1] OpenAI. OpenAI o1 System Card[R]. OpenAI Technical Report, 2024.

---

[⬅️ 上一节:LLM的能力与边界](3.3-LLM的能力与边界.md) | [🏠 返回目录](README.md) | [➡️ 下一节:习题与讨论](3.5-习题与讨论.md)
