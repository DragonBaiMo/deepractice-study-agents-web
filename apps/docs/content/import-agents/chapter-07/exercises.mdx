---
title: "习题与讨论"
description: "7.7 习题与讨论"
---

# 7.7 习题与讨论

> **提示**：以下的部分习题没有标准答案，旨在帮助学习者深入理解智能体的核心范式（ReAct、Plan-and-Solve、Reflection），并通过实践掌握不同范式的适用场景和实现方法。

---

## 概念理解题

### 习题 1：三大范式对比分析

ReAct、Plan-and-Solve、Reflection 是智能体设计的三大核心范式。请分析：

1. **核心思想**：
   - 用一句话描述每种范式的核心思想
   - 它们分别解决了什么问题？

2. **适用场景**：

| 范式 | 最适合的场景 | 不适合的场景 |
|-----|------------|------------|
| ReAct | | |
| Plan-and-Solve | | |
| Reflection | | |

3. **组合使用**：
   - 这三种范式可以组合吗？如何组合？
   - 举一个需要同时使用多种范式的场景。

---

### 习题 2：ReAct 深度理解

ReAct（Reasoning + Acting）强调思考与行动的交替进行。请分析：

1. **Thought-Action-Observation 循环**：
   - 每个环节的作用是什么？
   - 为什么需要 Observation 环节？直接 Thought-Action 行不行？

2. **终止条件设计**：
   - ReAct 循环何时应该终止？
   - 设计一个"智能终止"机制，避免无限循环。

3. **错误恢复**：
   - 如果某次 Action 失败了，下一个 Thought 应该如何处理？
   - 设计一个错误恢复策略。

---

### 习题 3：Plan-and-Solve 分析

Plan-and-Solve 将问题分解为规划和执行两个阶段。请分析：

1. **规划的粒度**：
   - 规划应该细到什么程度？
   - 太粗和太细各有什么问题？

2. **动态调整**：
   - 如果执行过程中发现计划不可行，应该怎么办？
   - 设计一个"计划修正"机制。

3. **与 ReAct 的关系**：
   - Plan-and-Solve 的执行阶段可以用 ReAct 吗？
   - 这样组合有什么好处？

---

## 设计与分析题

### 习题 4：实现 ReAct 智能体

设计一个使用 ReAct 范式的"**信息查询助手**"，能够：
- 接收用户的问题
- 使用搜索工具查找信息
- 综合多个来源给出答案

**要求**：

1. **定义工具集**：
```python
tools = [
    {
        "name": "search",
        "description": "搜索互联网信息",
        "parameters": {...}
    },
    {
        "name": "calculator",
        "description": "进行数学计算",
        "parameters": {...}
    }
]
```

2. **设计 Prompt 模板**：
   - System Prompt：定义智能体行为
   - 循环 Prompt：引导 Thought-Action-Observation

3. **实现循环逻辑**：
```python
def react_loop(question, max_iterations=5):
    # 你的实现
    pass
```

4. **测试用例**：
   - "特斯拉的市值是多少美元？"
   - "北京到上海的高铁票价是多少？加上出租车费大概需要多少钱？"

---

### 习题 5：实现 Plan-and-Solve 智能体

设计一个使用 Plan-and-Solve 范式的"**旅行规划助手**"：

**场景**：用户想要规划一次 3 天的北京之旅

**要求**：

1. **规划阶段**：
   - 生成一个结构化的旅行计划
   - 包括：行程安排、预算估算、注意事项

2. **执行阶段**：
   - 按计划查询具体信息（景点门票、酒店价格等）
   - 遇到问题时调整计划

3. **输出格式**：
```markdown
## 旅行计划

### Day 1
- 上午：[景点] - [预计费用]
- 下午：[景点] - [预计费用]
- 晚上：[住宿] - [预计费用]

### Day 2
...

### 总预算估算
- 交通：¥XXX
- 住宿：¥XXX
- 门票：¥XXX
- 餐饮：¥XXX
- 合计：¥XXX
```

---

### 习题 6：实现 Reflection 机制

在习题 4 或习题 5 的基础上，添加 Reflection（反思）机制：

**要求**：

1. **自评估**：
   - 智能体完成任务后，评估自己的表现
   - 识别可以改进的地方

2. **反思 Prompt 设计**：
```
请反思刚才的任务执行过程：

1. 做得好的地方：
2. 可以改进的地方：
3. 如果重新来一次，会怎么做：
4. 学到的经验：
```

3. **经验积累**：
   - 将反思结果存储为记忆
   - 下次遇到类似任务时，先 recall 相关经验

---

## 思考探索题

### 习题 7：范式选择的艺术

面对一个新任务，如何选择合适的范式？请设计一个决策框架：

1. **任务特征分析**：
   - 任务是否需要外部工具？
   - 任务是否可以分解为多个步骤？
   - 任务是否需要迭代优化？

2. **决策树设计**：
```
任务 → 需要工具吗？
        ├── 是 → 步骤明确吗？
        │         ├── 是 → Plan-and-Solve
        │         └── 否 → ReAct
        └── 否 → 需要迭代优化吗？
                  ├── 是 → Reflection
                  └── 否 → 直接生成
```

3. **混合策略**：
   - 设计一个"自适应范式选择器"
   - 根据任务特征自动选择范式

---

### 习题 8：范式的局限性

每种范式都有其局限性。请分析：

1. **ReAct 的局限**：
   - 过度依赖工具调用的问题
   - 循环次数难以控制的问题
   - 可能的改进方向

2. **Plan-and-Solve 的局限**：
   - 计划可能过于僵化
   - 对不确定性的处理不够灵活
   - 可能的改进方向

3. **Reflection 的局限**：
   - 反思可能流于形式
   - 自我评估的准确性问题
   - 可能的改进方向

---

## 动手实践题

### 习题 9：综合实践 - 构建全能助手

构建一个能够自动选择范式的"**全能助手**"：

**功能要求**：
1. 接收各种类型的任务
2. 自动分析任务特征
3. 选择合适的范式（或组合）
4. 执行任务并返回结果

**实现步骤**：

1. **任务分类器**：
```python
def classify_task(task):
    """
    分析任务特征，返回推荐的范式
    """
    # 你的实现
    pass
```

2. **范式执行器**：
```python
def execute_with_react(task): ...
def execute_with_plan_solve(task): ...
def execute_with_reflection(task): ...
```

3. **统一接口**：
```python
def smart_assistant(task):
    paradigm = classify_task(task)
    if paradigm == "react":
        return execute_with_react(task)
    elif paradigm == "plan_solve":
        return execute_with_plan_solve(task)
    # ...
```

4. **测试用例**：
   - "帮我查一下明天北京的天气" → 应选择 ReAct
   - "帮我规划一周的学习计划" → 应选择 Plan-and-Solve
   - "帮我改进这篇文章" → 应选择 Reflection

---

## 讨论与交流

本章学习过程中遇到问题？想与其他学习者交流心得？

在这里你可以:
- ✅ 讨论不同范式的实践经验
- ✅ 分享你的范式实现代码
- ✅ 交流范式选择的技巧
- ✅ 获得社区的帮助和反馈

---

## 参考文献

[1] YAO S, ZHAO J, YU D, et al. ReAct: Synergizing reasoning and acting in language models[C]//ICLR. 2023.

[2] WANG L, XU W, LAN Y, et al. Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large language models[C]//ACL. 2023.

[3] SHINN N, CASSANO F, LABASH B, et al. Reflexion: Language agents with verbal reinforcement learning[C]//NeurIPS. 2023.

---

[⬅️ 上一节：本章小结](7.6-本章小结.md) | [🏠 返回目录](README.md)
