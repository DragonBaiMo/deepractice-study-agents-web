---
title: "习题与讨论"
description: "3.5 习题与讨论"
---

# 3.5 习题与讨论

> **提示**：以下的部分习题没有标准答案，旨在帮助学习者深入理解大语言模型的能力边界，并培养设计高质量 Prompt 的实践能力。

---

## 概念理解题

### 习题 1：语言模型演进分析

从 N-gram 到 Transformer，语言模型经历了多次范式转变。请分析：

1. N-gram 模型的核心假设是什么？它为什么无法处理长距离依赖？

2. Word2Vec 的"词向量"与 N-gram 的"词频统计"有什么本质区别？这种区别带来了哪些能力提升？

3. Transformer 的"自注意力机制"解决了什么问题？它与 RNN 的"循环结构"相比有什么优势？

<details>
<summary>💡 思考提示</summary>

- N-gram 的马尔可夫假设
- 分布式表示 vs 离散表示
- 并行计算 vs 序列计算
- 上下文窗口的限制

</details>

---

### 习题 2：涌现现象理解

大语言模型的"涌现"现象是近年来 AI 领域最令人惊讶的发现之一。请思考：

1. 什么是"涌现"？为什么说它是"量变引起质变"的体现？

2. 举例说明三种在小模型中不存在、但在大模型中突然出现的能力。

3. 涌现现象对我们设计智能体系统有什么启示？我们应该如何利用这些涌现能力？

<details>
<summary>💡 思考提示</summary>

- 参考 Wei et al. 2022 的涌现能力研究
- 考虑：思维链推理、少样本学习、代码生成
- 思考：如何通过 Prompt 激发涌现能力

</details>

---

## 设计与分析题

### 习题 3：System Prompt 设计实践

假设你需要为一个"**代码审查助手**"设计 System Prompt，它需要：
- 审查 Pull Request 中的代码变更
- 识别潜在的 bug、安全漏洞和性能问题
- 给出具体的改进建议
- 解释问题的原因和修复方案

**要求**：

1. 设计一个完整的 System Prompt，包含角色定义、任务说明、输出格式和约束条件

2. 识别这个角色可能存在的**上下文鸿沟**（AI 不知道但角色必须知道的信息），并说明如何填补

3. 设计 2-3 个测试用例来验证你的 Prompt 效果

<details>
<summary>💡 设计提示</summary>

**角色定义要点**：
- 专业身份：资深代码审查员
- 审查风格：严谨但友好
- 关注维度：正确性、安全性、可读性、性能

**上下文鸿沟识别**：
- 团队的代码规范
- 项目的技术栈约定
- 历史 bug 模式

**输出格式建议**：
```markdown
## 审查结果

### 🔴 严重问题
- [位置] 问题描述
  - 原因分析
  - 修复建议

### 🟡 建议改进
...
```

</details>

---

### 习题 4：推理能力边界探索

大语言模型的推理能力存在明显的边界。请设计实验来探索这些边界：

1. **算术推理边界**：设计一组从简单到复杂的算术题，测试模型在什么复杂度下开始出错

2. **逻辑推理边界**：设计包含不同深度逻辑链的推理题，测试模型能处理多深的推理链

3. **常识推理边界**：设计需要结合多个常识知识的问题，测试模型在什么情况下会产生"幻觉"

**要求**：
- 每类至少设计 5 个测试用例
- 记录模型的表现（正确/错误/幻觉）
- 分析规律并总结边界条件

<details>
<summary>💡 实验设计提示</summary>

**算术推理示例**：
- 简单：2位数加减法
- 中等：3位数乘法
- 复杂：多步混合运算
- 边界：大数运算、小数精度

**逻辑推理示例**：
- 1步推理："如果 A，则 B。A 成立，所以？"
- 3步推理：三段论链
- 5步推理：复杂因果链

</details>

---

## 思考探索题

### 习题 5：RAG 与记忆的本质区别

本章提出"RAG 不是真正的记忆"这一观点。请深入思考：

1. RAG（检索增强生成）的工作原理是什么？它解决了什么问题？

2. 人类的"记忆"与 RAG 的"检索"有什么本质区别？请从以下维度分析：
   - 主动性 vs 被动性
   - 联想性 vs 精确匹配
   - 遗忘曲线 vs 永久存储
   - 情感关联 vs 纯语义关联

3. 如果要设计一个更接近人类记忆的 AI 系统，你认为需要具备哪些特性？

---

### 习题 6：Prompt 工程的哲学思考

本章强调"Prompt 的本质是传递认知框架，而非传递信息"。请思考：

1. 什么是"认知框架"？它与"信息"有什么区别？

2. 为什么说"告诉 AI 怎么思考"比"告诉 AI 你是谁"更重要？

3. 如果把 Prompt 设计类比为"教育"，那么：
   - 好的 Prompt 设计师应该像什么样的老师？
   - 什么是"授人以鱼"vs"授人以渔"在 Prompt 设计中的体现？

---

## 动手实践题

### 习题 7：构建多轮对话 Prompt 系统

设计一个能够进行多轮对话的 Prompt 系统，用于**技术面试模拟**：

**基本要求**：
1. 定义面试官角色（可选择：前端/后端/算法面试官）
2. 设计面试流程（自我介绍 → 技术问题 → 项目经验 → 反问环节）
3. 实现难度递进机制（根据回答质量调整下一题难度）

**进阶要求**：
4. 设计评分标准和反馈机制
5. 处理候选人的"不知道"或"跑题"情况
6. 模拟真实面试中的追问行为

<details>
<summary>💡 实现提示</summary>

**多轮对话结构**：
```
System: 面试官角色定义 + 面试流程 + 评分标准

User: [开始面试]
Assistant: 欢迎！请先简单介绍一下自己...

User: [自我介绍]
Assistant: [根据介绍内容，引出第一个技术问题]

User: [技术回答]
Assistant: [评估回答 + 追问或下一题]
...
```

**难度控制**：
- 记录每题得分
- 连续答对 → 提升难度
- 答错 → 降低难度或换方向

</details>

---

### 习题 8：探索思维链（Chain-of-Thought）

思维链提示是提升 LLM 推理能力的重要技术。请进行以下实践：

1. **零样本 CoT**：
   - 选择一个复杂的数学应用题
   - 对比"直接回答"和"添加'让我们一步步思考'"的效果差异

2. **少样本 CoT**：
   - 为同类型问题设计 2-3 个带推理过程的示例
   - 测试示例质量对模型表现的影响

3. **自一致性（Self-Consistency）**：
   - 让模型对同一问题生成多个推理路径
   - 分析不同路径的结果一致性

**记录要求**：
- 每个实验的 Prompt 设计
- 模型的完整输出
- 你的分析和发现

---

## 讨论与交流

本章学习过程中遇到问题？想与其他学习者交流心得？

在这里你可以:
- ✅ 提问习题相关问题
- ✅ 分享你的 Prompt 设计经验
- ✅ 讨论 LLM 能力边界的发现
- ✅ 获得社区的帮助和反馈

---

## 参考文献

[1] VASWANI A, SHAZEER N, PARMAR N, et al. Attention is all you need[C]//Advances in Neural Information Processing Systems. 2017: 5998-6008.

[2] WEI J, TAY Y, BOMMASANI R, et al. Emergent abilities of large language models[J]. arXiv preprint arXiv:2206.07682, 2022.

[3] WEI J, WANG X, SCHUURMANS D, et al. Chain-of-thought prompting elicits reasoning in large language models[C]//Advances in Neural Information Processing Systems. 2022.

[4] BROWN T B, MANN B, RYDER N, et al. Language models are few-shot learners[C]//Advances in Neural Information Processing Systems. 2020: 1877-1901.

---

[⬅️ 上一节：从LLM到智能体架构](3.4-从LLM到智能体架构.md) | [🏠 返回目录](README.md)
